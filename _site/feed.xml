<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-28T01:35:19+05:30</updated><id>http://localhost:4000/</id><title type="html">Tejan Karmali</title><subtitle>Here, I share my experience during GSoC and Deep learning.</subtitle><entry><title type="html">GSoC’18: Week 1 and 2</title><link href="http://localhost:4000/jekyll/update/2018/05/26/post2.html" rel="alternate" type="text/html" title="GSoC'18: Week 1 and 2" /><published>2018-05-26T16:00:00+05:30</published><updated>2018-05-26T16:00:00+05:30</updated><id>http://localhost:4000/jekyll/update/2018/05/26/post2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/26/post2.html">&lt;p&gt;Hello, world!&lt;/p&gt;

&lt;p&gt;The commmunity bonding period and first week of GSoC has come to an end. Community bonding period lasted over three weeks. I coult not do much work over first two weeks due to my end semester exams. In the third week, I implemented &lt;a href=&quot;https://arxiv.org/abs/1502.03509&quot;&gt;MADE&lt;/a&gt;, which is Masked Autoencoder for Distributed Estimation.  I also added dilation feature for convolutions (which was a &lt;a href=&quot;https://github.com/FluxML/NNlib.jl/pull/31#issuecomment-386673632&quot;&gt;feature request&lt;/a&gt; for NNlib.jl).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/FluxML/model-zoo/pull/39&quot;&gt;PR#19&lt;/a&gt;: Implemented MADE architecture in Flux.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/FluxML/NNlib.jl/pull/40&quot;&gt;PR#40&lt;/a&gt;: Dilation support for convolutions. So far, dilation support is available for 1D, 2D and 3D convolutions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In week 1, I implemented and created demos of some seminal papers in deep reinforcement learning. The algorithms implemented were tested on environments in OpenAI Gym using the package &lt;a href=&quot;https://github.com/JuliaML/OpenAIGym.jl&quot;&gt;OpenAIGym.jl&lt;/a&gt;. Environments used for testing are CartPole-v0, Pong-v0 and Pendulum-v0. The work done in this regard over pre-GSoC period and this week has been compiled into &lt;a href=&quot;https://github.com/tejank10/Flux-baselines&quot;&gt;Flux baselines&lt;/a&gt; repo. As of now it contains 6 models, which include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/dqn/dqn.jl&quot;&gt;Deep Q Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/dqn/double-dqn.jl&quot;&gt;Double DQN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/dqn/prioritized-replay-dqn.jl&quot;&gt;Prioritized Experience Replay DQN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/dqn/duel-dqn.jl&quot;&gt;Dueling DDQN &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/actor-critic/a2c.jl&quot;&gt;Advantage Actor-Critic&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tejank10/Flux-baselines/blob/master/ddpg/ddpg.jl&quot;&gt;Deep Deterministic Policy Gradients&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In week 2, I started working towards one major milestone of the project: the &lt;a href=&quot;https://deepmind.com/blog/alphago-zero-learning-scratch/&quot;&gt;AlphaGo Zero&lt;/a&gt; model. For those of you not familiar, AlphaGo Zero is latest version of AlphaGo which is a program to play (and defeat :P) the ancient Chinese game of Go. This version of AlphaGo doesn’t take any human amateur and professional games to learn how to play Go. Instead it learns to play by playing games against itself, starting from completely random play.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/tejank10/AlphaGo.jl&quot;&gt;AlphaGo.jl&lt;/a&gt; is where I am implementing the Flux based version of AlphaGo Zero. This part of project is divided  into three tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Creating the environment for Go&lt;/li&gt;
  &lt;li&gt;Monte-Carlo Tree Search&lt;/li&gt;
  &lt;li&gt;Main model of AlphaGo Zero using Go and MCTS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In week 2 I created the environment of Go. The environment simulates the game of Go, with abstraction like that of OpenAI Gym. The game can be played on a board of size 9x9, 13x13, 17x17 or 19x19. A player is assigned stones of either black or white color. The player with black stones makes the first move. Now, this can be an advantage for the black player. Hence white player is awarded some extra points. These extra points are called komi. Players can place a stone on any intersection of a vertical and horizontal lines on the board. A &lt;em&gt;NxN&lt;/em&gt; board has &lt;em&gt;N^2&lt;/em&gt; intersections.  On a player’s turn, he can either place a stone or can pass to the other player. Thus, action space for the environment is &lt;em&gt;N^2 + 1&lt;/em&gt;. The game ends when both the players pass consecutively. Depending on the end game state of the board, scores are calculated and winner is decided.&lt;/p&gt;

&lt;p&gt;In the coming days, my goals will be to complete the other two tasks. Hopefully in the next blog post, I’ll present the demo of the game before you.&lt;/p&gt;</content><author><name></name></author><summary type="html">Hello, world!</summary></entry><entry><title type="html">Accepted to GSoC’18</title><link href="http://localhost:4000/jekyll/update/2018/05/04/post1.html" rel="alternate" type="text/html" title="Accepted to GSoC'18" /><published>2018-05-04T16:00:00+05:30</published><updated>2018-05-04T16:00:00+05:30</updated><id>http://localhost:4000/jekyll/update/2018/05/04/post1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/04/post1.html">&lt;p&gt;Hello, world!&lt;/p&gt;

&lt;p&gt;I am Tejan Karmali, a CS undergrad at NIT Goa. My proposal for GSoC’18 has been &lt;a href=&quot;https://summerofcode.withgoogle.com/projects/#5885584111828992&quot;&gt;accepted&lt;/a&gt; under NumFOCUS: Julia. I’ll be working on enriching the model zoo of &lt;a href=&quot;http://fluxml.ai/&quot;&gt;Flux.jl&lt;/a&gt;. Flux is a Machine Learning library written fully in Julia. My project aims at adding a variety of models in Flux. I’ll be adding Dueling DQN, Actor-Critic model, AlphaGo, DCGAN, Decoupling Neural Interface and Spatial Transformer Networks in the model zoo over the course of summer. These models are targeted towards the new users of Flux and to help them get started.&lt;/p&gt;

&lt;p&gt;My mentors are &lt;a href=&quot;https://mikeinnes.github.io/&quot;&gt;Mike Innes&lt;/a&gt;, &lt;a href=&quot;https://simondanisch.jimdo.com/&quot;&gt;Simon Danisch&lt;/a&gt;, &lt;a href=&quot;http://chrisrackauckas.com/&quot;&gt;Chris Rackauckas&lt;/a&gt; and &lt;a href=&quot;http://karpinski.org/&quot;&gt;Stefan Karpinski&lt;/a&gt;. I’ll be posting biweekly updates here about my project. Looking forward to an eventful and productive summer!&lt;/p&gt;</content><author><name></name></author><summary type="html">Hello, world!</summary></entry></feed>